{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Resources</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Global stuff</center></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import json\n",
    "import ast\n",
    "import sys\n",
    "import os\n",
    "import cProfile\n",
    "import time\n",
    "import functools # For creating a user-defined comparison operator\n",
    "from scipy import stats # For Kendall Tau\n",
    "from scipy.spatial.distance import pdist, squareform # For L1 / L2 norm\n",
    "import subprocess # For importing missing libraries real-time\n",
    "try:\n",
    "    import pyprof2calltree\n",
    "except:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pyprof2calltree'])\n",
    "    import pyprof2calltree\n",
    "try:\n",
    "    from pydpp.dpp import DPP # Implements DPP\n",
    "except:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pydpp'])\n",
    "    from pydpp.dpp import DPP\n",
    "try:\n",
    "    import tikzplotlib # Required for generating Latex plot scripts\n",
    "except:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'tikzplotlib'])\n",
    "    import tikzplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem description\n",
    "_ = parser.add_argument(\"--nb_criteria\",\n",
    "                        help=\"Number of criteria for the ground truth decision maker\",\n",
    "                        type=int,\n",
    "                        default=11)\n",
    "_ = parser.add_argument(\"--nb_profiles\",\n",
    "                        help=\"Number of profiles for the ground truth decision maker\",\n",
    "                        type=int,\n",
    "                        default=3)\n",
    "_ = parser.add_argument(\"--nb_alternatives\",\n",
    "                        help=\"Number of alternatives from which to draw comparisons to submit to the decision maker\",\n",
    "                        type=int,\n",
    "                        default=50)\n",
    "_ = parser.add_argument(\"--eval_on_test_set_1\",\n",
    "                        help=\"Indicates if we evaluate generalization ability on unseen comparisons of the train alternatives\",\n",
    "                        type=ast.literal_eval,\n",
    "                        default=True)\n",
    "_ = parser.add_argument(\"--nb_alternatives_test_set_2\",\n",
    "                        help=\"Number of alternatives to evaluate generalization ability on unseen alternatives\",\n",
    "                        type=int,\n",
    "                        default=300)\n",
    "_ = parser.add_argument(\"--nb_comparisons\",\n",
    "                        help=\"Number of comparisons of alternatives to submit to the decision maker\",\n",
    "                        type=int,\n",
    "                        default=100)\n",
    "_ = parser.add_argument(\"--debug_mode\",\n",
    "                        help=\"To add plots in the script\",\n",
    "                        type=ast.literal_eval,\n",
    "                        default=False)\n",
    "_ = parser.add_argument(\"--random_seed\",\n",
    "                        help=\"Experiment random seed\",\n",
    "                        type=int,\n",
    "                        default=None)\n",
    "_ = parser.add_argument(\"--output_directory\",\n",
    "                        help=\"Directory where to produce figures\",\n",
    "                        type=str,\n",
    "                        default=\"../output/learn_SRMP/\")\n",
    "_ = parser.add_argument(\"--save_diversity\",\n",
    "                        help=\"To save diversity data into a csv\",\n",
    "                        type=ast.literal_eval,\n",
    "                        default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'mutation_random_profile_perturbation'\n",
    "_ = parser.add_argument(\"--mutation_random_profile_perturbation__perturbation_scale\",\n",
    "                        help=\"Argument 'perturbation_scale' of function 'mutation_random_profile_perturbation'\",\n",
    "                        type=float,\n",
    "                        default=0.1)\n",
    "_ = parser.add_argument(\"--mutation_random_profile_perturbation__individual_criterion_proba\",\n",
    "                        help=\"Argument 'individual_criterion_proba' of function 'mutation_random_profile_perturbation'\",\n",
    "                        type=float,\n",
    "                        default=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'mutation_random_weights_perturbation'\n",
    "_ = parser.add_argument(\"--mutation_random_weights_perturbation__perturbation_scale\",\n",
    "                        help=\"Argument 'perturbation_scale' of function 'mutation_random_weights_perturbation'\",\n",
    "                        type=float,\n",
    "                        default=0.1)\n",
    "_ = parser.add_argument(\"--mutation_random_weights_perturbation__individual_criterion_proba\",\n",
    "                        help=\"Argument 'individual_criterion_proba' of function 'mutation_random_weights_perturbation'\",\n",
    "                        type=float,\n",
    "                        default=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'mutation_shrink_profiles'\n",
    "_ = parser.add_argument(\"--mutation_shrink_profiles__shrink_factor\",\n",
    "                        help=\"Argument 'shrink_factor' of function 'mutation_shrink_profiles'\",\n",
    "                        type=float,\n",
    "                        default=0.7)\n",
    "_ = parser.add_argument(\"--mutation_shrink_profiles__individual_criterion_proba\",\n",
    "                        help=\"Argument 'individual_criterion_proba' of function 'mutation_shrink_profiles'\",\n",
    "                        type=float,\n",
    "                        default=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'mutation_expand_profiles'\n",
    "_ = parser.add_argument(\"--mutation_expand_profiles__expand_factor\",\n",
    "                        help=\"Argument 'expand_factor' of function 'mutation_expand_profiles'\",\n",
    "                        type=float,\n",
    "                        default=0.7)\n",
    "_ = parser.add_argument(\"--mutation_expand_profiles__individual_criterion_proba\",\n",
    "                        help=\"Argument 'individual_criterion_proba' of function 'mutation_expand_profiles'\",\n",
    "                        type=float,\n",
    "                        default=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'prepare_new_population'\n",
    "_ = parser.add_argument(\"--prepare_new_population__elitism_ratio\",\n",
    "                        help=\"Argument 'elitism_ratio' of function 'prepare_new_population'\",\n",
    "                        type=float,\n",
    "                        default=0.4)\n",
    "_ = parser.add_argument(\"--prepare_new_population__random_ratio\",\n",
    "                        help=\"Argument 'random_ratio' of function 'prepare_new_population'\",\n",
    "                        type=float,\n",
    "                        default=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'select_solutions'\n",
    "_ = parser.add_argument(\"--select_solutions__nb_solutions\",\n",
    "                        help=\"Argument 'nb_solutions' of function 'select_solutions'\",\n",
    "                        type=int,\n",
    "                        default=2)\n",
    "_ = parser.add_argument(\"--select_solutions__strategy\",\n",
    "                        help=\"Argument 'strategy' of function 'select_solutions'\",\n",
    "                        type=str,\n",
    "                        choices=[\"roulette\", \"DPP\", \"DPP+roulette\", \"uniform\"],\n",
    "                        default=\"DPP\")\n",
    "_ = parser.add_argument(\"--select_solutions__similarity_metric\",\n",
    "                        help=\"Argument 'metric' of function 'compute_similarity_matrix'\",\n",
    "                        type=str,\n",
    "                        choices=[\"kendall-tau\", \"spearman-rho\", \"l1-norm\", \"l2-norm\"],\n",
    "                        default=\"l1-norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'make_crossover'\n",
    "_ = parser.add_argument(\"--make_crossover__crossover_swap_weights_probability\",\n",
    "                        help=\"Partial argument 'crossover_probability' of function 'make_crossover'\",\n",
    "                        type=float,\n",
    "                        default=0.0)\n",
    "_ = parser.add_argument(\"--make_crossover__crossover_swap_orders_probability\",\n",
    "                        help=\"Partial argument 'crossover_probability' of function 'make_crossover'\",\n",
    "                        type=float,\n",
    "                        default=0.0)\n",
    "_ = parser.add_argument(\"--make_crossover__crossover_swap_profiles_probability\",\n",
    "                        help=\"Partial argument 'crossover_probability' of function 'make_crossover'\",\n",
    "                        type=float,\n",
    "                        default=0.0)\n",
    "_ = parser.add_argument(\"--make_crossover__crossover_mix_criteria_probability\",\n",
    "                        help=\"Partial argument 'crossover_probability' of function 'make_crossover'\",\n",
    "                        type=float,\n",
    "                        default=0.5)\n",
    "_ = parser.add_argument(\"--make_crossover__crossover_mix_criteria_and_weights_probability\",\n",
    "                        help=\"Partial argument 'crossover_probability' of function 'make_crossover'\",\n",
    "                        type=float,\n",
    "                        default=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'make_mutation'\n",
    "_ = parser.add_argument(\"--make_mutation__mutation_random_profile_perturbation_probability\",\n",
    "                        help=\"Partial argument 'mutation_probability' of function 'make_mutation'\",\n",
    "                        type=float,\n",
    "                        default=0.0)\n",
    "_ = parser.add_argument(\"--make_mutation__mutation_random_weights_perturbation_probability\",\n",
    "                        help=\"Partial argument 'mutation_probability' of function 'make_mutation'\",\n",
    "                        type=float,\n",
    "                        default=0.2)\n",
    "_ = parser.add_argument(\"--make_mutation__mutation_shrink_profiles_probability\",\n",
    "                        help=\"Partial argument 'mutation_probability' of function 'make_mutation'\",\n",
    "                        type=float,\n",
    "                        default=0.2)\n",
    "_ = parser.add_argument(\"--make_mutation__mutation_expand_profiles_probability\",\n",
    "                        help=\"Partial argument 'mutation_probability' of function 'make_mutation'\",\n",
    "                        type=float,\n",
    "                        default=0.0)\n",
    "_ = parser.add_argument(\"--make_mutation__mutation_partially_reverse_order_probability\",\n",
    "                        help=\"Partial argument 'mutation_probability' of function 'make_mutation'\",\n",
    "                        type=float,\n",
    "                        default=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'keep_or_drop_children'\n",
    "_ = parser.add_argument(\"--keep_or_drop_children__survival_probability\",\n",
    "                        help=\"Argument 'survival_probability' of function 'keep_or_drop_children'\",\n",
    "                        type=float,\n",
    "                        default=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arguments of function 'estimate_decision_maker'\n",
    "_ = parser.add_argument(\"--estimate_decision_maker__return_k_best\",\n",
    "                        help=\"Argument 'return_k_best' of function 'estimate_decision_maker'\",\n",
    "                        type=int,\n",
    "                        default=1)\n",
    "_ = parser.add_argument(\"--estimate_decision_maker__population_size\",\n",
    "                        help=\"Argument 'population_size' of function 'estimate_decision_maker'\",\n",
    "                        type=int,\n",
    "                        default=100)\n",
    "_ = parser.add_argument(\"--estimate_decision_maker__stop_after_non_evolving\",\n",
    "                        help=\"Argument 'stop_after_non_evolving' of function 'estimate_decision_maker'\",\n",
    "                        type=int,\n",
    "                        default=50)\n",
    "_ = parser.add_argument(\"--estimate_decision_maker__check_identical_ratio\",\n",
    "                        help=\"Argument 'check_identical_ratio' of function 'estimate_decision_maker'\",\n",
    "                        type=float,\n",
    "                        default=0.1)\n",
    "_ = parser.add_argument(\"--estimate_decision_maker__nb_profiles\",\n",
    "                        help=\"Argument 'nb_profiles' of function 'estimate_decision_maker'\",\n",
    "                        type=int,\n",
    "                        default=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and transmit to functions file\n",
    "try :\n",
    "    get_ipython()\n",
    "    ARGS = parser.parse_args(args=[])\n",
    "except :\n",
    "    ARGS = parser.parse_args()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Other stuff</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "if ARGS.random_seed != None :\n",
    "    numpy.random.seed(ARGS.random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Functions</center></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Misc</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg_value (argument_name, user_provided_value) :\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Retrieves the default value for an argument if needed.\n",
    "        --\n",
    "        In:\n",
    "            * argument_name: Argument to retrieve.\n",
    "            * user_provided_value: Value provided to the argument by the user.\n",
    "        Out:\n",
    "            * argument: Value of the asked argument.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # User gets precedence, then we check global variable\n",
    "    if user_provided_value is not None :\n",
    "        return user_provided_value\n",
    "    elif argument_name in ARGS :\n",
    "        return ARGS.__dict__[argument_name]\n",
    "    else :\n",
    "        raise Exception(\"No default value provided for argument '\" + argument_name + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_profiling () :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Starts profiling execution times in the code.\n",
    "        --\n",
    "        In:\n",
    "            * None.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Create global object\n",
    "    global profiler\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_profiling () :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Stops profiling execution times in the code, and shows results.\n",
    "        --\n",
    "        In:\n",
    "            * None.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Get stats and visualize\n",
    "    global profiler\n",
    "    profiler.create_stats()\n",
    "    pyprof2calltree.visualize(profiler.getstats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_for (file_name) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Creates the directory for the given file name if it does not exist.\n",
    "        --\n",
    "        In:\n",
    "            * file_name: Directory to create, or file for which we want to create a directory.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Creates the corresponding directory\n",
    "    dir_name = os.path.dirname(file_name)\n",
    "    os.makedirs(dir_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv (data, file_name, separator=\";\") :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Saves experimental data into a csv file in column form.\n",
    "        --\n",
    "        In:\n",
    "            * data: List of experimental data to append to a csv file.\n",
    "            * file_name: Directory to create, or csv file for which we want to create a directory.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # If file already exists, append new a column\n",
    "    if os.path.exists(file_name) :\n",
    "        df = pd.read_csv(file_name, sep=separator)\n",
    "        new_column = pd.DataFrame({f'EX_{df.shape[1]+1}': data})\n",
    "        df = df.merge(new_column, left_index=True, right_index=True)\n",
    "\n",
    "    # Create a new dataframe if file is not found\n",
    "    else :\n",
    "        df = pd.DataFrame({'EX_1': data})\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(file_name, index=False, sep=separator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plotting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_maker (decision_maker, alternatives=[], title=\"\", file_name=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Plots a decision maker.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker: Decision maker to plot.\n",
    "            * alternatives: List of alternatives to plot with the decision maker.\n",
    "            * title: Complementary information to plot in the title.\n",
    "            * file_name: Where to save the results.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Vertical bars\n",
    "    figure = pyplot.figure(figsize=(20, 10))\n",
    "    nb_criteria = decision_maker[\"profiles\"].shape[1]\n",
    "    for i in range(nb_criteria) :\n",
    "        pyplot.plot([i, i], [0, 1], \"k\")\n",
    "\n",
    "    # Profiles\n",
    "    nb_profiles = decision_maker[\"profiles\"].shape[0]\n",
    "    for i in range(nb_profiles) :\n",
    "        plotted = pyplot.plot(range(nb_criteria), decision_maker[\"profiles\"][i], \":*\")\n",
    "        pyplot.text(-0.02 * nb_criteria, decision_maker[\"profiles\"][i][0], \"p\" + str(i), color=plotted[-1].get_color())\n",
    "        pyplot.text(nb_criteria - 1 + 0.01 * nb_criteria, decision_maker[\"profiles\"][i][-1], \"p\" + str(i), color=plotted[-1].get_color())\n",
    "    \n",
    "    # Alternatives\n",
    "    for alternative in alternatives :\n",
    "        plotted = pyplot.plot(range(nb_criteria), alternative[\"profile\"], \"-*\", label=alternative[\"id\"])\n",
    "        pyplot.text(-0.02 * nb_criteria, alternative[\"profile\"][0], \"a\" + str(alternative[\"id\"]), color=plotted[-1].get_color())\n",
    "        pyplot.text(nb_criteria - 1 + 0.01 * nb_criteria, alternative[\"profile\"][-1], \"a\" + str(alternative[\"id\"]), color=plotted[-1].get_color())\n",
    "    \n",
    "    # Plot decorations\n",
    "    pyplot.xticks(range(nb_criteria), [\"w\" + str(i) + \" =\\n\" + str(decision_maker[\"weights\"][i]) for i in range(nb_criteria)], rotation=45)\n",
    "    pyplot.yticks([0, 1])\n",
    "    figure.gca().set_frame_on(False)\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.title(\"dm\" + str(decision_maker[\"id\"]) + \"\\n\" + \" -> \".join(\"p\" + str(o) for o in decision_maker[\"order\"]) + (\"\\n\" + title if title != \"\" else \"\"))\n",
    "    pyplot.show()\n",
    "    \n",
    "    # Save\n",
    "    if file_name is not None :\n",
    "        create_directory_for(file_name)\n",
    "        figure.savefig(file_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix (matrix, rows_labels=\"\", cols_labels=\"\", rows_title=\"\", cols_title=\"\", title=\"\", colorbar=False, round_values=None, file_name=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Plots a matrix.\n",
    "        --\n",
    "        In:\n",
    "            * matrix: Matrix to plot.\n",
    "            * rows_labels: Labels associated with the rows.\n",
    "            * cols_labels: Labels associated with the columns.\n",
    "            * title: Figure title.\n",
    "            * colorbar: Set to True to plot a colorbar.\n",
    "            * round_values: Set to >= 0 to plot values in matrix cells.\n",
    "            * file_name: Where to save the results.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Plot matrix\n",
    "    figure, axis = pyplot.subplots(figsize=(20, 20))\n",
    "    cax = axis.matshow(matrix)\n",
    "    \n",
    "    # Add colorbar\n",
    "    if colorbar :\n",
    "        pyplot.colorbar(cax)\n",
    "    \n",
    "    # Add values\n",
    "    if round_values is not None :\n",
    "        color_change_threshold = 0.5 * (numpy.max(matrix) + numpy.min(matrix))\n",
    "        for i in range(matrix.shape[0]) :\n",
    "            for j in range(matrix.shape[1]) :\n",
    "                value = round(matrix[i, j], round_values) if round_values > 0 else int(matrix[i, j])\n",
    "                color = \"black\" if matrix[i, j] > color_change_threshold else \"white\"\n",
    "                axis.text(j, i, str(value), va=\"center\", ha=\"center\", color=color)\n",
    "    \n",
    "    # Plot\n",
    "    pyplot.title(title)\n",
    "    pyplot.yticks(range(matrix.shape[0]))\n",
    "    pyplot.ylabel(rows_title)\n",
    "    pyplot.gca().set_yticklabels(rows_labels)\n",
    "    pyplot.xticks(range(matrix.shape[1]))\n",
    "    pyplot.xlabel(cols_title)\n",
    "    pyplot.gca().set_xticklabels(cols_labels)\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.show()\n",
    "    \n",
    "    # Save\n",
    "    if file_name is not None :\n",
    "        create_directory_for(file_name)\n",
    "        figure.savefig(file_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves (xs, ys, legends=[], styles=[], xlabel=\"\", ylabel=\"\", title=\"\", vertical_asymptote=None, vertical_asymptote_label=\"\", file_name=None, latex_name=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Plots multiple curves.\n",
    "        --\n",
    "        In:\n",
    "            * xs: X coordinates (one per curve, or one for all curves).\n",
    "            * ys: Y coordinates (one per curve).\n",
    "            * legends: Legends to associate with the curve (one per curve, or nothing).\n",
    "            * styles: Styles of the curves (one per curve, or nothing).\n",
    "            * xlabel: X axis label.\n",
    "            * ylabel: Y axis label.\n",
    "            * title: Figure title.\n",
    "            * vertical_asymptote: Optional vertical asymptote.\n",
    "            * vertical_asymptote_label: Label of the optional vertical asymptote.\n",
    "            * file_name: Image file name to save the results.\n",
    "            * latex_name: Latex script name to save the results.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Plot\n",
    "    figure = pyplot.figure(figsize=(20, 10))\n",
    "    for i in range(len(ys)) :\n",
    "        actual_legend = \"\" if len(legends) == 0 else legends[i]\n",
    "        actual_styles = \"\" if len(styles) == 0 else styles[i]\n",
    "        pyplot.plot(xs[i], ys[i], actual_styles, label=actual_legend)\n",
    "    pyplot.xlabel(xlabel)\n",
    "    pyplot.ylabel(ylabel)\n",
    "    if len(legends) > 0 :\n",
    "        pyplot.legend()\n",
    "    pyplot.title(title)\n",
    "    figure.gca().spines[\"right\"].set_visible(False)\n",
    "    figure.gca().spines[\"top\"].set_visible(False)\n",
    "    pyplot.tight_layout()\n",
    "    if vertical_asymptote is not None:\n",
    "        pyplot.axvline(x=vertical_asymptote, linewidth=2, color='green', label=vertical_asymptote_label)\n",
    "        pyplot.legend()\n",
    "    #pyplot.show()    \n",
    "    \n",
    "    # Save pyplot figures into an image file\n",
    "    if file_name is not None :\n",
    "        create_directory_for(file_name)\n",
    "        figure.savefig(file_name, bbox_inches=\"tight\")\n",
    "\n",
    "    # Save plot as Latex plot script\n",
    "    if latex_name is not None :\n",
    "        create_directory_for(latex_name)\n",
    "        tikzplotlib.save(latex_name, flavor=\"context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars (bars=[], legends=[], xticklabels=[], ylabel=\"\", title=\"\", show_max=True, file_name=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Plots multiple bars.\n",
    "        --\n",
    "        In:\n",
    "            * bars: List of bars to plot (one per bar).\n",
    "            * legends: Legends to associate with the bars (one per bar).\n",
    "            * xticklabels: X axis labels for groups of bars.\n",
    "            * ylabel: Y axis label.\n",
    "            * title: Figure title.\n",
    "            * show_max: Boolean indicating if we draw line for the max of all bars.\n",
    "            * file_name: Where to save the results.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Plot\n",
    "    figure, axis = pyplot.subplots(figsize=(len(bars[0]), 10))\n",
    "    width = 1.0 / (1 + len(bars))\n",
    "    xs = numpy.arange(len(bars[0]))\n",
    "    for i in range(len(bars)) :\n",
    "        axis.bar(xs - width * 0.5 * (1 + len(bars)) + width * (i + 1), bars[i], width, label=legends[i])\n",
    "        if show_max :\n",
    "            axis.plot([-1, len(bars[0])], [max(bars[i]), max(bars[i])], \"--\")\n",
    "    axis.set_ylabel(ylabel)\n",
    "    axis.set_xticks(xs)\n",
    "    axis.set_xticklabels(xticklabels, rotation=90)\n",
    "    axis.set_title(title)\n",
    "    axis.legend()\n",
    "    axis.margins(x=0.0)\n",
    "    figure.tight_layout()\n",
    "    pyplot.show()\n",
    "    \n",
    "    # Save\n",
    "    if file_name is not None :\n",
    "        create_directory_for(file_name)\n",
    "        figure.savefig(file_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Problem description</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blank_decision_maker () :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Creates a blank decision maker.\n",
    "        --\n",
    "        In:\n",
    "            * None.\n",
    "        Out:\n",
    "            * decision_maker: Created decision maker, formatted as a dictionary, with only ID set.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # We add a unique id to the decision maker\n",
    "    global decision_maker_ids_counter\n",
    "    if \"decision_maker_ids_counter\" not in globals() :\n",
    "        decision_maker_ids_counter = 0\n",
    "    else :\n",
    "        decision_maker_ids_counter += 1\n",
    "\n",
    "    # Let's create the object\n",
    "    decision_maker = {\"weights\": None,\n",
    "                      \"profiles\": None,\n",
    "                      \"order\": None,\n",
    "                      \"id\": decision_maker_ids_counter}\n",
    "    \n",
    "    # Done\n",
    "    return decision_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_decision_maker (decision_maker) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Corrects a decision maker.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker: Decision maker to correct.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Profiles in [0, 1] and sorted\n",
    "    decision_maker[\"profiles\"][decision_maker[\"profiles\"] < 0.0] = 0.0\n",
    "    decision_maker[\"profiles\"][decision_maker[\"profiles\"] > 1.0] = 1.0\n",
    "    decision_maker[\"profiles\"] = -numpy.sort(-decision_maker[\"profiles\"], axis=0)\n",
    "    \n",
    "    # Weights in ]0, 1] and with 1-sum\n",
    "    nb_criteria = decision_maker[\"profiles\"].shape[1]\n",
    "    decision_maker[\"weights\"][decision_maker[\"weights\"] < 0.0] = 1.0 / nb_criteria\n",
    "    decision_maker[\"weights\"][decision_maker[\"weights\"] > 1.0] = 1.0\n",
    "    decision_maker[\"weights\"] /= numpy.sum(decision_maker[\"weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_decision_maker (nb_criteria, nb_profiles) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Creates a random decision maker.\n",
    "        --\n",
    "        In:\n",
    "            * nb_criteria: Number of criteria.\n",
    "            * nb_profiles: Number of profiles to generate.\n",
    "        Out:\n",
    "            * decision_maker: Randomly created decision maker, formatted as a dictionary.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Random weights and profiles\n",
    "    decision_maker = create_blank_decision_maker()\n",
    "    decision_maker[\"weights\"] = numpy.random.rand(nb_criteria)\n",
    "    decision_maker[\"profiles\"] = numpy.random.uniform(0.0, 1.0, (nb_profiles, nb_criteria))\n",
    "    correct_decision_maker(decision_maker)\n",
    "    \n",
    "    # We choose an order for the profiles\n",
    "    order = numpy.array(range(nb_profiles))\n",
    "    numpy.random.shuffle(order)\n",
    "    decision_maker[\"order\"] = order\n",
    "\n",
    "    # Done\n",
    "    return decision_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decision_maker_copy (decision_maker_to_copy) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Copies a given decision maker, associating a new ID to it.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker_to_copy: Decision maker used as a basis for the new one.\n",
    "        Out:\n",
    "            * decision_maker: Copy of the decision maker, formatted as a dictionary.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # We copy everything except ID\n",
    "    decision_maker = create_blank_decision_maker()\n",
    "    decision_maker[\"weights\"] = numpy.copy(decision_maker_to_copy[\"weights\"])\n",
    "    decision_maker[\"profiles\"] = numpy.copy(decision_maker_to_copy[\"profiles\"])\n",
    "    decision_maker[\"order\"] = numpy.copy(decision_maker_to_copy[\"order\"])\n",
    "\n",
    "    # Done\n",
    "    return decision_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_alternative (nb_criteria) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Creates a random alternative.\n",
    "        --\n",
    "        In:\n",
    "            * nb_criteria: Number of criteria.\n",
    "        Out:\n",
    "            * alternative: Created alternative, formatted as a dictionary.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # An alternative is a profile\n",
    "    profile = numpy.random.uniform(0.0, 1.0, nb_criteria)\n",
    "\n",
    "    # We add a unique id to the alternative\n",
    "    global alternative_ids_counter\n",
    "    if \"alternative_ids_counter\" not in globals() :\n",
    "        alternative_ids_counter = 0\n",
    "    else :\n",
    "        alternative_ids_counter += 1\n",
    "\n",
    "    # Let's create the alternative\n",
    "    alternative = {\"profile\": profile,\n",
    "                   \"id\": alternative_ids_counter}\n",
    "\n",
    "    # Done\n",
    "    return alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_concordance (decision_maker, discriminating_profile, alternative) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Returns the concordance of an alternative with respect to a reference profile.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker: Reference decision maker used to compute concordance of the alternative.\n",
    "            * discriminating_profile: Number of the profile to use in the decision maker's profiles.\n",
    "            * alternative: Alternative for which we want to compute concordance.\n",
    "        Out:\n",
    "            * result: Concordance for the alternative.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Sum of weights for all criteria above discriminating profile\n",
    "    result = numpy.dot(alternative[\"profile\"] >= decision_maker[\"profiles\"][discriminating_profile], decision_maker[\"weights\"].transpose())\n",
    "    \n",
    "    # Done\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_preference (decision_maker, alternative_1, alternative_2) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Check which is preferred between two alternatives according to given decision maker.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker: Reference decision maker used to compare alternatives.\n",
    "            * alternative_1: First alternative to compare.\n",
    "            * alternative_2: Second alternative to compare.\n",
    "        Out:\n",
    "            * preferred: Alternative in {alternative_1, alternative_2} which is preferred, or None if there is no preference.\n",
    "            * discriminating_profile: Profile used in the decision maker to determine preference, or None if there is no preference.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Default value if no alternative is preferred to the other\n",
    "    preferred, discriminating_profile = None, None\n",
    "    \n",
    "    # We check preferred profiles in the given order\n",
    "    for i in decision_maker[\"order\"] :\n",
    "        alternative_1_concordance = compute_concordance(decision_maker, i, alternative_1)\n",
    "        alternative_2_concordance = compute_concordance(decision_maker, i, alternative_2)\n",
    "        if alternative_1_concordance > alternative_2_concordance :\n",
    "            return alternative_1, i\n",
    "        elif alternative_1_concordance < alternative_2_concordance :\n",
    "            return alternative_2, i\n",
    "    \n",
    "    # Done\n",
    "    return preferred, discriminating_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_preferences (decision_maker, alternatives) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Checks all preference relations among alternatives according to given decision maker.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker: Reference decision maker used to compare alternatives.\n",
    "            * alternatives: List of alternatives to compare.\n",
    "        Out:\n",
    "            * discriminating_profiles: Matrix (sorted in increasing IDs) of profiles used in the decision maker to determine dominance, with -1 entries if there is no dominance.\n",
    "            * preferences: Matrix (sorted in increasing IDs) of dominances, where result_dominances[i][j] == 1 if alternative i dominates alternative j, -1 if there is no dominance, and 0 otherwise.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # Alternatives are sorted in increasing ID for the matrix\n",
    "    sorted_alternatives = sorted(alternatives, key=lambda obj : obj[\"id\"])\n",
    "    nb_alternatives = len(sorted_alternatives)\n",
    "    \n",
    "    # We return a matrix indicating which profile is used for determining preference, and another indicating which alternative is preferred\n",
    "    discriminating_profiles = numpy.zeros((nb_alternatives, nb_alternatives)) - 1\n",
    "    preferences = numpy.zeros((nb_alternatives, nb_alternatives)) - 1\n",
    "    \n",
    "    # We check all pairs\n",
    "    for alternative_1 in range(nb_alternatives) :\n",
    "        for alternative_2 in range(alternative_1 + 1, nb_alternatives) :\n",
    "            preferred, discriminating_profile = check_preference(decision_maker, sorted_alternatives[alternative_1], sorted_alternatives[alternative_2])\n",
    "            if preferred is not None :\n",
    "                discriminating_profiles[alternative_1, alternative_2] = discriminating_profile\n",
    "                discriminating_profiles[alternative_2, alternative_1] = discriminating_profiles[alternative_1, alternative_2]\n",
    "                preferences[alternative_1, alternative_2] = int(preferred[\"id\"] == alternatives[alternative_1][\"id\"])\n",
    "                preferences[alternative_2, alternative_1] = 1 - preferences[alternative_1, alternative_2]\n",
    "    \n",
    "    # Done\n",
    "    return discriminating_profiles, preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_comparisons (decision_maker, alternatives, nb_comparisons) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Returns a subset of all possible comparisons, along with the decision maker's decision regarding them.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker: Reference decision maker used to compare alternatives.\n",
    "            * alternatives: List of alternatives to compare.\n",
    "            * nb_comparisons: Number of random comparisons to make.\n",
    "        Out:\n",
    "            * results: Subsampled list of comparisons, consisting of tuples (alternative_1, alternative_2, preferred), where preferred is in {alternative_1, alternative_2, None)}.\n",
    "            * sampling_matrix: Matrix (sorted in increasing IDs) indicating which comparisons have been sampled.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Alternatives are sorted in increasing ID for the matrix\n",
    "    sorted_alternatives = sorted(alternatives, key=lambda obj : obj[\"id\"])\n",
    "    nb_alternatives = len(sorted_alternatives)\n",
    "    \n",
    "    # We get random distinct pairs of alternative\n",
    "    all_pairs = numpy.array(numpy.triu_indices(nb_alternatives, 1))\n",
    "    sampled_indices = numpy.random.choice(range(all_pairs.shape[1]), nb_comparisons, replace=False)\n",
    "    sampled_pairs = all_pairs[:, sampled_indices]\n",
    "    \n",
    "    # We make a sampling matrix\n",
    "    sampling_matrix = numpy.zeros((nb_alternatives, nb_alternatives))\n",
    "    sampling_matrix[sampled_pairs[0], sampled_pairs[1]] = 1\n",
    "    sampling_matrix[sampled_pairs[1], sampled_pairs[0]] = 1\n",
    "\n",
    "    # We compare them\n",
    "    results = []\n",
    "    for i in sampled_indices :\n",
    "        preferred, discriminating_profile = check_preference(decision_maker, sorted_alternatives[all_pairs[0][i]], sorted_alternatives[all_pairs[1][i]])\n",
    "        results += [(sorted_alternatives[all_pairs[0][i]], sorted_alternatives[all_pairs[1][i]], preferred)]\n",
    "\n",
    "    # Done\n",
    "    return results, sampling_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_verified_comparisons (decision_maker, expected_results) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Counts the number of comparisons that are verified by a solution.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker: Solution to evaluate.\n",
    "            * expected_results: Provided comparisons, along with their preference relation.\n",
    "        Out:\n",
    "            * percentage_success: Percentage of verified comparisons.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Fitness (to maximize) is the percentage of correct predictions\n",
    "    correct_predictions = 0\n",
    "    for alternative_1, alternative_2, expected_preferred in expected_results :\n",
    "        preferred, discriminating_profile = check_preference(decision_maker, alternative_1, alternative_2)\n",
    "        if (preferred is None and expected_preferred is None) or (preferred is not None and expected_preferred is not None and preferred[\"id\"] == expected_preferred[\"id\"]) :\n",
    "            correct_predictions += 1\n",
    "    percentage_success = correct_predictions / len(expected_results)\n",
    "    \n",
    "    # Done\n",
    "    return percentage_success"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Problem resolution</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_swap_weights (solutions) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Swaps weights of the parents.\n",
    "        --\n",
    "        In:\n",
    "            * solutions: Solutions to mix, along with their fitness scores.\n",
    "        Out:\n",
    "            * new_solutions: Produced new solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # We swap weights of the parents\n",
    "    new_solutions = []\n",
    "    for i in range(len(solutions)) :\n",
    "        for j in range(i + 1, len(solutions)) :\n",
    "            child_1 = create_blank_decision_maker()\n",
    "            child_1[\"weights\"] = numpy.copy(solutions[j][1][\"weights\"])\n",
    "            child_1[\"profiles\"] = numpy.copy(solutions[i][1][\"profiles\"])\n",
    "            child_1[\"order\"] = numpy.copy(solutions[i][1][\"order\"])\n",
    "            child_2 = create_blank_decision_maker()\n",
    "            child_2[\"weights\"] = numpy.copy(solutions[i][1][\"weights\"])\n",
    "            child_2[\"profiles\"] = numpy.copy(solutions[j][1][\"profiles\"])\n",
    "            child_2[\"order\"] = numpy.copy(solutions[j][1][\"order\"])\n",
    "            new_solutions += [child_1, child_2]\n",
    "        \n",
    "    # Done\n",
    "    return new_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_swap_orders (solutions) :\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Swaps orders of the parents.\n",
    "        --\n",
    "        In:\n",
    "            * solutions: Solutions to mix, along with their fitness scores.\n",
    "        Out:\n",
    "            * new_solutions: Produced new solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # We swap orders of the parents\n",
    "    new_solutions = []\n",
    "    for i in range(len(solutions)) :\n",
    "        for j in range(i + 1, len(solutions)) :\n",
    "            child_1 = create_blank_decision_maker()\n",
    "            child_1[\"weights\"] = numpy.copy(solutions[i][1][\"weights\"])\n",
    "            child_1[\"profiles\"] = numpy.copy(solutions[i][1][\"profiles\"])\n",
    "            child_1[\"order\"] = numpy.copy(solutions[j][1][\"order\"])\n",
    "            child_2 = create_blank_decision_maker()\n",
    "            child_2[\"weights\"] = numpy.copy(solutions[j][1][\"weights\"])\n",
    "            child_2[\"profiles\"] = numpy.copy(solutions[j][1][\"profiles\"])\n",
    "            child_2[\"order\"] = numpy.copy(solutions[i][1][\"order\"])\n",
    "            new_solutions += [child_1, child_2]\n",
    "    \n",
    "    # Done\n",
    "    return new_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_swap_profiles (solutions) :\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Swaps profiles of the parents.\n",
    "        --\n",
    "        In:\n",
    "            * solutions: Solutions to mix, along with their fitness scores.\n",
    "        Out:\n",
    "            * new_solutions: Produced new solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # We swap orders of the parents\n",
    "    new_solutions = []\n",
    "    for i in range(len(solutions)) :\n",
    "        for j in range(i + 1, len(solutions)) :\n",
    "            child_1 = create_blank_decision_maker()\n",
    "            child_1[\"weights\"] = numpy.copy(solutions[i][1][\"weights\"])\n",
    "            child_1[\"profiles\"] = numpy.copy(solutions[j][1][\"profiles\"])\n",
    "            child_1[\"order\"] = numpy.copy(solutions[i][1][\"order\"])\n",
    "            child_2 = create_blank_decision_maker()\n",
    "            child_2[\"weights\"] = numpy.copy(solutions[j][1][\"weights\"])\n",
    "            child_2[\"profiles\"] = numpy.copy(solutions[i][1][\"profiles\"])\n",
    "            child_2[\"order\"] = numpy.copy(solutions[j][1][\"order\"])\n",
    "            new_solutions += [child_1, child_2]\n",
    "    \n",
    "    # Done\n",
    "    return new_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_mix_criteria (solutions) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Mixes criteria from the parents randomly, both the profiles and associated weights.\n",
    "        --\n",
    "        In:\n",
    "            * solutions: Solutions to mix, along with their fitness scores.\n",
    "        Out:\n",
    "            * new_solutions: Produced new solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # We take bits of parents randomly\n",
    "    new_solutions = []\n",
    "    for i in range(len(solutions)) :\n",
    "        for j in range(i + 1, len(solutions)) :\n",
    "            index_vector = numpy.random.choice([i, j], solutions[i][1][\"profiles\"].shape[1])\n",
    "            child_1 = create_decision_maker_copy(solutions[i][1])\n",
    "            child_1[\"profiles\"][:, numpy.where(index_vector == j)] = solutions[j][1][\"profiles\"][:, numpy.where(index_vector == j)]\n",
    "            child_1[\"weights\"][numpy.where(index_vector == j)] = solutions[j][1][\"weights\"][numpy.where(index_vector == j)]\n",
    "            child_2 = create_decision_maker_copy(solutions[j][1])\n",
    "            child_2[\"profiles\"][:, numpy.where(index_vector == i)] = solutions[i][1][\"profiles\"][:, numpy.where(index_vector == i)]\n",
    "            child_2[\"weights\"][numpy.where(index_vector == i)] = solutions[i][1][\"weights\"][numpy.where(index_vector == i)]\n",
    "            new_solutions += [child_1, child_2]\n",
    "    \n",
    "    # Correction to remain valid\n",
    "    for new_solution in new_solutions :\n",
    "        correct_decision_maker(new_solution)\n",
    "    \n",
    "    # Done\n",
    "    return new_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_mix_criteria_and_weights (solutions) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Mixes criteria and weights from the parents randomly.\n",
    "        --\n",
    "        In:\n",
    "            * solutions: Solutions to mix, along with their fitness scores.\n",
    "        Out:\n",
    "            * new_solutions: Produced new solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # We take bits of parents randomly\n",
    "    new_solutions = []\n",
    "    for i in range(len(solutions)) :\n",
    "        for j in range(i + 1, len(solutions)) :\n",
    "            index_vector_criteria = numpy.random.choice([i, j], solutions[i][1][\"profiles\"].shape[1])\n",
    "            index_vector_weights = numpy.random.choice([i, j], solutions[i][1][\"profiles\"].shape[1])\n",
    "            child_1 = create_decision_maker_copy(solutions[i][1])\n",
    "            child_1[\"profiles\"][:, numpy.where(index_vector_criteria == j)] = solutions[j][1][\"profiles\"][:, numpy.where(index_vector_criteria == j)]\n",
    "            child_1[\"weights\"][numpy.where(index_vector_weights == j)] = solutions[j][1][\"weights\"][numpy.where(index_vector_weights == j)]\n",
    "            child_2 = create_decision_maker_copy(solutions[j][1])\n",
    "            child_2[\"profiles\"][:, numpy.where(index_vector_criteria == i)] = solutions[i][1][\"profiles\"][:, numpy.where(index_vector_criteria == i)]\n",
    "            child_2[\"weights\"][numpy.where(index_vector_weights == i)] = solutions[i][1][\"weights\"][numpy.where(index_vector_weights == i)]\n",
    "            new_solutions += [child_1, child_2]\n",
    "    \n",
    "    # Correction to remain valid\n",
    "    for new_solution in new_solutions :\n",
    "        correct_decision_maker(new_solution)\n",
    "    \n",
    "    # Done\n",
    "    return new_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_random_profile_perturbation (solution, perturbation_scale=None, individual_criterion_proba=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Randomly perturbates profiles.\n",
    "        --\n",
    "        In:\n",
    "            * solution: Solution to mutate.\n",
    "            * perturbation_scale: Importance of the random permutation.\n",
    "            * individual_criterion_proba: Probability to apply mutation to a criterion.\n",
    "        Out:\n",
    "            * mutated_solution: Mutated input.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    perturbation_scale = get_arg_value(\"mutation_random_profile_perturbation__perturbation_scale\", perturbation_scale)\n",
    "    individual_criterion_proba = get_arg_value(\"mutation_random_profile_perturbation__individual_criterion_proba\", individual_criterion_proba)\n",
    "\n",
    "    # We randomly perturbates profiles\n",
    "    mutated_solution = create_decision_maker_copy(solution)\n",
    "    nb_criteria = mutated_solution[\"profiles\"].shape[1]\n",
    "    nb_profiles = mutated_solution[\"profiles\"].shape[0]\n",
    "    for i in range(nb_criteria) :\n",
    "        if numpy.random.rand() < individual_criterion_proba :\n",
    "            mutated_solution[\"profiles\"][:, i] += (numpy.random.rand(nb_profiles) * 2.0 - 1.0) * perturbation_scale\n",
    "    \n",
    "    # Correction to remain valid\n",
    "    correct_decision_maker(mutated_solution)\n",
    "    \n",
    "    # Done\n",
    "    return mutated_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_random_weights_perturbation (solution, perturbation_scale=None, individual_criterion_proba=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Randomly perturbates weights.\n",
    "        --\n",
    "        In:\n",
    "            * solution: Solution to mutate.\n",
    "            * perturbation_scale: Importance of the random permutation.\n",
    "            * individual_criterion_proba: Probability to apply mutation to a criterion.\n",
    "        Out:\n",
    "            * mutated_solution: Mutated input.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    perturbation_scale = get_arg_value(\"mutation_random_weights_perturbation__perturbation_scale\", perturbation_scale)\n",
    "    individual_criterion_proba = get_arg_value(\"mutation_random_weights_perturbation__individual_criterion_proba\", individual_criterion_proba)\n",
    "\n",
    "    # We randomly perturbates profiles\n",
    "    mutated_solution = create_decision_maker_copy(solution)\n",
    "    nb_criteria = mutated_solution[\"profiles\"].shape[1]\n",
    "    for i in range(nb_criteria) :\n",
    "        mutated_solution[\"weights\"][i] += (numpy.random.rand() * 2.0 - 1.0) * perturbation_scale\n",
    "    \n",
    "    # Correction to remain valid\n",
    "    correct_decision_maker(mutated_solution)\n",
    "    \n",
    "    # Done\n",
    "    return mutated_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_shrink_profiles (solution, shrink_factor=None, individual_criterion_proba=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Shrinks the profiles.\n",
    "        --\n",
    "        In:\n",
    "            * solution: Solution to mutate.\n",
    "            * shrink_factor: Importance of the shrinking.\n",
    "            * individual_criterion_proba: Probability to apply mutation to a criterion.\n",
    "        Out:\n",
    "            * mutated_solution: Mutated input.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    shrink_factor = get_arg_value(\"mutation_shrink_profiles__shrink_factor\", shrink_factor)\n",
    "    individual_criterion_proba = get_arg_value(\"mutation_shrink_profiles__individual_criterion_proba\", individual_criterion_proba)\n",
    "\n",
    "    # We shrink profiles\n",
    "    mutated_solution = create_decision_maker_copy(solution)\n",
    "    nb_criteria = mutated_solution[\"profiles\"].shape[1]\n",
    "    for i in range(nb_criteria) :\n",
    "        if numpy.random.rand() < individual_criterion_proba :\n",
    "            mutated_solution[\"profiles\"][:, i] = mutated_solution[\"profiles\"][:, i] / (1.0 + shrink_factor)\n",
    "            mutated_solution[\"profiles\"][:, i] -= numpy.mean(mutated_solution[\"profiles\"][:, i], axis=0)\n",
    "            mutated_solution[\"profiles\"][:, i] += numpy.mean(solution[\"profiles\"][:, i], axis=0)\n",
    "    \n",
    "    # Correction to remain valid\n",
    "    correct_decision_maker(mutated_solution)\n",
    "    \n",
    "    # Done\n",
    "    return mutated_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_expand_profiles (solution, expand_factor=None, individual_criterion_proba=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Expands the profiles.\n",
    "        --\n",
    "        In:\n",
    "            * solution: Solution to mutate.\n",
    "            * expand_factor: Importance of the expansion.\n",
    "            * individual_criterion_proba: Probability to apply mutation to a criterion.\n",
    "        Out:\n",
    "            * mutated_solution: Mutated input.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    expand_factor = get_arg_value(\"mutation_expand_profiles__expand_factor\", expand_factor)\n",
    "    individual_criterion_proba = get_arg_value(\"mutation_expand_profiles__individual_criterion_proba\", individual_criterion_proba)\n",
    "\n",
    "    # We shrink profiles\n",
    "    mutated_solution = create_decision_maker_copy(solution)\n",
    "    nb_criteria = mutated_solution[\"profiles\"].shape[1]\n",
    "    for i in range(nb_criteria) :\n",
    "        if numpy.random.rand() < individual_criterion_proba :\n",
    "            mutated_solution[\"profiles\"][:, i] = mutated_solution[\"profiles\"][:, i] * (1.0 + expand_factor)\n",
    "            mutated_solution[\"profiles\"][:, i] -= numpy.mean(mutated_solution[\"profiles\"][:, i], axis=0)\n",
    "            mutated_solution[\"profiles\"][:, i] += numpy.mean(solution[\"profiles\"][:, i], axis=0)\n",
    "    \n",
    "    # Correction to remain valid\n",
    "    correct_decision_maker(mutated_solution)\n",
    "    \n",
    "    # Done\n",
    "    return mutated_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_partially_reverse_order (solution) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Partially reverses the order.\n",
    "        --\n",
    "        In:\n",
    "            * solution: Solution to mutate.\n",
    "        Out:\n",
    "            * mutated_solution: Mutated input.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # We reverse a random subpath\n",
    "    nb_profiles = solution[\"profiles\"].shape[0]\n",
    "    start = numpy.random.randint(0, nb_profiles - 1)\n",
    "    stop = numpy.random.randint(start, nb_profiles)\n",
    "    mutated_solution = create_decision_maker_copy(solution)\n",
    "    mutated_solution[\"order\"][start:stop] = numpy.flip(mutated_solution[\"order\"][start:stop])\n",
    "    \n",
    "    # Correction to remain valid\n",
    "    #correct_decision_maker(mutated_solution)\n",
    "    \n",
    "    # Done\n",
    "    return mutated_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_population (population_size, nb_profiles, expected_results) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Generates a population of initial solution.\n",
    "        --\n",
    "        In:\n",
    "            * population_size: Number of random solutions to produce.\n",
    "            * nb_profiles: Number of profiles to give to random solutions.\n",
    "            * expected_results: Provided comparisons, along with their preference relation.\n",
    "        Out:\n",
    "            * population: List of created decision makers, along with their fitnesses.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # We generate random solutions independently\n",
    "    nb_criteria = len(expected_results[0][0][\"profile\"])\n",
    "    population = [create_random_decision_maker(nb_criteria, nb_profiles) for i in range(population_size)]\n",
    "    \n",
    "    # We sort them in decreasing fitness\n",
    "    population = [(compute_fitness(solution, expected_results), solution) for solution in population]\n",
    "    population = sorted(population, key=lambda obj : -obj[0])\n",
    "    \n",
    "    # Done\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_new_population (population, nb_profiles, expected_results, elitism_ratio=None, random_ratio=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Initializes a new population from an existing one.\n",
    "        --\n",
    "        In:\n",
    "            * population: Population as generated by the previous iteration.\n",
    "            * nb_profiles: Number of profiles to give to random solutions.\n",
    "            * expected_results: Provided comparisons, along with their preference relation.\n",
    "            * elitism_ratio: Percentage of the population size to fill with best solutions.\n",
    "            * random_ratio: Percentage of the population to fill with random solutions.\n",
    "        Out:\n",
    "            * new_population: Initialized new population.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    elitism_ratio = get_arg_value(\"prepare_new_population__elitism_ratio\", elitism_ratio)\n",
    "    random_ratio = get_arg_value(\"prepare_new_population__random_ratio\", random_ratio)\n",
    "\n",
    "    # We keep some of the best solutions from previous iteration (at least one)\n",
    "    population_size = len(population)\n",
    "    nb_best_solutions = max(1, int(elitism_ratio * population_size))\n",
    "    new_population = population[:nb_best_solutions]\n",
    "\n",
    "    # We add new random solutions\n",
    "    nb_criteria = population[0][1][\"profiles\"].shape[1]\n",
    "    new_random_solutions = [create_random_decision_maker(nb_criteria, nb_profiles) for i in range(int(random_ratio * population_size))]\n",
    "    new_population += [(compute_fitness(solution, expected_results), solution) for solution in new_random_solutions]\n",
    "    \n",
    "    # Done\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fitness (solution, expected_results) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Returns a fitness score for a solution.\n",
    "        --\n",
    "        In:\n",
    "            * solution: Solution to evaluate.\n",
    "            * expected_results: Provided comparisons, along with their preference relation.\n",
    "        Out:\n",
    "            * fitness: Fitness score.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Fitness (to maximize) is the percentage of correct predictions\n",
    "    fitness = count_verified_comparisons(solution, expected_results)\n",
    "    \n",
    "    # Done\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_decision_maker(population):\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Vectorizes all the genomes of a population and stores them in an array.\n",
    "        --\n",
    "        In:\n",
    "            * Population of solutions of a given generation along with their fitnesses.\n",
    "            \n",
    "        Out:\n",
    "            * flattened_population: Array of vectorized genomes of a population.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Create empty list of vectorized genomes\n",
    "    flattened_population = []\n",
    "\n",
    "    # Vectorize all the genomes and append them to a population list\n",
    "    for dm in range(len(population)):\n",
    "      profile = population[dm][1][\"profiles\"].flatten()\n",
    "      array_weight = numpy.concatenate((profile, population[dm][1][\"weights\"]))\n",
    "      flattened_population.append(array_weight)\n",
    "\n",
    "    # Convert the data into a numpy array\n",
    "    flattened_population = numpy.array(flattened_population)\n",
    "    \n",
    "    #Done\n",
    "    return flattened_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_decision_maker_alternatives (decision_maker, alternatives) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Ranks all alternatives according to given decision maker.\n",
    "        --\n",
    "        In:\n",
    "            * decision_maker: Reference decision maker used to rank alternatives.\n",
    "            * alternatives: List of alternatives to rank.\n",
    "        Out:\n",
    "            * ranking_vector: Vector containing the alternatives ranking for a given position maker where the first element is the best ranked alternative.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Inner user-defined comparison operator\n",
    "    def compare(alternative_1, alternative_2):\n",
    "\n",
    "      # No preference among alternatives\n",
    "      if ( check_preference(decision_maker, alternative_1, alternative_2)[0] is None ):\n",
    "        return 0\n",
    "      # Alternative 1 > alternative 2\n",
    "      elif ( alternative_1['id'] == check_preference(decision_maker, alternative_1, alternative_2)[0]['id'] ):\n",
    "        return 1\n",
    "      # Alternative 2 > alternative 1\n",
    "      else:\n",
    "        return -1\n",
    "\n",
    "    # Sort (O(nlogn)) with user-defined comparison operator\n",
    "    ranked_alternatives = sorted(alternatives, key=functools.cmp_to_key(compare))\n",
    "    \n",
    "    # Extract vector with only ranked alternatives\n",
    "    ranking_vector = [ alternative['id'] for alternative in ranked_alternatives ]\n",
    "\n",
    "    #Done\n",
    "    return ranking_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_population_rankings (population, alternatives) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Computes the ranking of all the alternatives for every solution in the population.\n",
    "        --\n",
    "        In:\n",
    "            * population: Population of solutions of a given generation along with their fitnesses.\n",
    "            * alternatives: List of alternatives to rank.\n",
    "        Out:\n",
    "            * population_rankings: List of ranked alternatives vectors for all solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # Create empty list of rankings\n",
    "    population_rankings = []\n",
    "\n",
    "    # Append the ranking vector of each decision maker in population\n",
    "    for solution in population:    \n",
    "        population_rankings.append( rank_decision_maker_alternatives(solution[1], alternatives) )\n",
    "\n",
    "    # Done\n",
    "    return population_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix (solutions_representation, metric) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Constructs a similarity matrix for the population given a similarity metric between rankings.\n",
    "        --\n",
    "        In:\n",
    "            * solutions_representation: List of solutions represented in an appropriate structure for a given similarity metric.\n",
    "            * metric: Similarity metric used to compare alternative rankings.\n",
    "        Out:\n",
    "            * similarity_matrix: Matrix containing the pairwise similarity of all solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Compute similarity matrix of all decision makers' Kendall Tau's pairwise evaluation\n",
    "    if metric == \"kendall-tau\" :\n",
    "        similarity_matrix = numpy.array( [ [ ( (stats.kendalltau(p1, p2)[0] + 1) / 2  ) for p2 in solutions_representation ] for p1 in solutions_representation ] )\n",
    "\n",
    "    # Compute similarity matrix of all decision makers' Spearman Rho's pairwise evaluation\n",
    "    elif metric == \"spearman-rho\" :\n",
    "        similarity_matrix = numpy.array( [ [ ( (stats.spearmanr(p1, p2)[0] + 1) / 2  ) for p2 in solutions_representation ] for p1 in solutions_representation ] )\n",
    "\n",
    "    # Compute similarity matrix of all decision makers Manhattan distance pairwise evaluation\n",
    "    elif metric == \"l1-norm\" :\n",
    "        distances = squareform( pdist(solutions_representation, metric='cityblock') )\n",
    "        normalized_matrix = distances / distances.max()\n",
    "        similarity_matrix = 1 - normalized_matrix\n",
    "\n",
    "    # Compute similarity matrix of all decision makers' Euclidean distance pairwise evaluation\n",
    "    elif metric == \"l2-norm\" :\n",
    "        distances = squareform( pdist(solutions_representation, metric='euclidean') )\n",
    "        similarity_matrix = 1 / numpy.exp(distances)\n",
    "\n",
    "    # Weird choice\n",
    "    else :\n",
    "        raise Exception(\"Unimplemented metric '\" + metric + \"' for function 'compute_similarity_matrix'\")\n",
    "\n",
    "    #Done\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive_definite (similarity_matrix) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Checks if a similarity matrix is positive definite.\n",
    "        --\n",
    "        In:\n",
    "            * similarity_matrix: Precomputed similarity matrix of a population following the global similarity metric.\n",
    "        Out:\n",
    "            * positive_definite: Boolean indicating whether the similarity matrix is positive definite or not.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Compute the eignevalues of the similarity matrix\n",
    "    eigenvalues = numpy.linalg.eigvals(similarity_matrix)\n",
    "\n",
    "    # If all eigenvalues are strictly positive, then the matrix is positive definite. \n",
    "    positive_definite = numpy.all(eigenvalues > 0)\n",
    "\n",
    "    #Done\n",
    "    return positive_definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diversity (similarity_matrix) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Computes the mean, standard deviation and variance of the similarity pairwise comparisons of a population.\n",
    "        --\n",
    "        In:\n",
    "            * similarity_matrix: Precomputed similarity matrix of a population following the global similarity metric.\n",
    "        Out:\n",
    "            * mean_similarity: Mean of pairwise comparisons of a population.\n",
    "            * std_similarity: Standard deviation of pairwise comparisons of a population.\n",
    "            * var_similarity: Variance of pairwise comparisons of a population.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Zero the diagonal and the upper triangle of the similarity matrix\n",
    "    ltri= numpy.tril(similarity_matrix, k=-1)\n",
    "    \n",
    "    # Fit in a single vector all the non-zero values of the transformed matrix\n",
    "    ltri = ltri[numpy.nonzero(ltri)]\n",
    "    \n",
    "    # Compute the mean, the standard deviation and the variance of the vector\n",
    "    mean_similarity = ltri.mean()\n",
    "    std_similarity = ltri.std()\n",
    "    var_similarity = ltri.var()\n",
    "\n",
    "    # Done\n",
    "    return mean_similarity, std_similarity, var_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kDPP_model (population, metric, alternatives=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Creates a k-determinantal point processes model for sampling given a population.\n",
    "        --\n",
    "        In:\n",
    "            * population: Population of solutions of a given generation along with their fitnesses.\n",
    "            * metric: Similarity metric used to compare alternative rankings.\n",
    "            * alternatives: List of alternatives to rank in case of of using a ranking correlation metric.\n",
    "        Out:\n",
    "            * dpp: k-DPP model with fitted data and computed kernel.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # If the similarity metric is based on ranking correlation, use population's rankings as kDPP input\n",
    "    if metric in {\"kendall-tau\", \"spearman-rho\"} :\n",
    "        dpp_input = compute_population_rankings(population, alternatives)\n",
    "    else:\n",
    "        dpp_input = flatten_decision_maker(population)\n",
    "\n",
    "    # Fit the data into a kDPP model instance and compute the internal kernel\n",
    "    dpp = DPP(dpp_input)\n",
    "    dpp.compute_kernel(kernel_func= lambda x : compute_similarity_matrix(x, metric))\n",
    "\n",
    "    #Done\n",
    "    return dpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_solutions (population, nb_solutions=None, strategy=None, sampler=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Selects solutions to mix from the population.\n",
    "        --\n",
    "        In:\n",
    "            * population: Population of solutions from where to pick solutions, along with their fitnesses.\n",
    "            * nb_solutions: Number of solutions to return.\n",
    "            * strategy: Strategy to use to select solutions.\n",
    "            * sampler: Pre-computed probabilistic model to generate samples.\n",
    "        Out:\n",
    "            * selected_solutions: Picked solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    nb_solutions = get_arg_value(\"select_solutions__nb_solutions\", nb_solutions)\n",
    "    strategy = get_arg_value(\"select_solutions__strategy\", strategy)\n",
    "\n",
    "    # Probabilities are based on fitness\n",
    "    if strategy == \"roulette\" :\n",
    "        probabilities = numpy.array([solution[0] for solution in population], dtype=float)\n",
    "        probabilities /= numpy.sum(probabilities)\n",
    "        selected_indices = numpy.random.choice(range(len(population)), nb_solutions, p=probabilities, replace=False)\n",
    "        selected_solutions = [population[i] for i in selected_indices]\n",
    "\n",
    "    # Use a metric-based similarity matrix of all decision makers as a DPP-sampling kernel to encourage diversity\n",
    "    elif strategy == \"DPP\" :\n",
    "        selected_indices = sampler.sample_k(nb_solutions)\n",
    "        selected_solutions = [population[i] for i in selected_indices]\n",
    "\n",
    "    # Combine DPP and roulette strategies to first look for diversity and then prioritize fitness among parents\n",
    "    elif strategy == \"DPP+roulette\" :\n",
    "\n",
    "        # DPP subsetting of 20% of a given population\n",
    "        nb_solutions_dpp = int(len(population) / 5)\n",
    "        dpp_indices = sampler.sample_k(nb_solutions_dpp)\n",
    "        dpp_solutions = [population[i] for i in dpp_indices]\n",
    "\n",
    "        # Roulette sample from the diverse subset\n",
    "        probabilities = numpy.array([solution[0] for solution in dpp_solutions], dtype=float)\n",
    "        probabilities /= numpy.sum(probabilities)\n",
    "        selected_indices = numpy.random.choice(range(len(dpp_solutions)), nb_solutions, p=probabilities, replace=False)\n",
    "        selected_solutions = [dpp_solutions[i] for i in selected_indices]\n",
    "\n",
    "    # Probability of being chosen follows a uniform probability distribution\n",
    "    elif strategy == \"uniform\" :\n",
    "        selected_indices = numpy.random.choice(range(len(population)), nb_solutions, replace=False)\n",
    "        selected_solutions = [population[i] for i in selected_indices]\n",
    "\n",
    "    # Weird choice\n",
    "    else :\n",
    "        raise Exception(\"Unimplemented strategy '\" + strategy + \"' for function 'select_solutions'\")\n",
    "    \n",
    "    # Done\n",
    "    return selected_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_crossover (solutions, crossover_probability=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Applies a crossover to some solutions to produce new ones.\n",
    "        --\n",
    "        In:\n",
    "            * solutions: Solutions to mix, along with their fitness scores.\n",
    "            * crossover_probability: Probability for any crossover to happen (should sum to 1, this is corrected if not the case).\n",
    "        Out:\n",
    "            * new_solutions: Produced new solutions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    crossover_probability = {\"crossover_swap_weights\" : get_arg_value(\"make_crossover__crossover_swap_weights_probability\", None if crossover_probability is None else crossover_probability[\"crossover_swap_weights\"]),\n",
    "                             \"crossover_swap_orders\" : get_arg_value(\"make_crossover__crossover_swap_orders_probability\", None if crossover_probability is None else crossover_probability[\"crossover_swap_orders\"]),\n",
    "                             \"crossover_swap_profiles\" : get_arg_value(\"make_crossover__crossover_swap_profiles_probability\", None if crossover_probability is None else crossover_probability[\"crossover_swap_profiles\"]),\n",
    "                             \"crossover_mix_criteria\" : get_arg_value(\"make_crossover__crossover_mix_criteria_probability\", None if crossover_probability is None else crossover_probability[\"crossover_mix_criteria\"]),\n",
    "                             \"crossover_mix_criteria_and_weights\" : get_arg_value(\"make_crossover__crossover_mix_criteria_and_weights_probability\", None if crossover_probability is None else crossover_probability[\"crossover_mix_criteria_and_weights\"])}\n",
    "    \n",
    "    # Apply a random crossover (only one)\n",
    "    probabilities = numpy.array(list(crossover_probability.values())) / numpy.sum(list(crossover_probability.values()))\n",
    "    crossover = numpy.random.choice(list(crossover_probability.keys()), 1, p=probabilities)[0]\n",
    "    if crossover in globals() :\n",
    "        new_solutions = globals()[crossover](solutions)\n",
    "    else :\n",
    "        sys.exit(\"Trying to perform nonexisting crossover: \" + str(crossover))\n",
    "    \n",
    "    # Done\n",
    "    return new_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mutation (solution, mutation_probability=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Applies mutation(s) to a solution.\n",
    "        --\n",
    "        In:\n",
    "            * solution: Solution to mutate.\n",
    "            * mutation_probability: Probability for any mutation to happen.\n",
    "        Out:\n",
    "            * mutated_solution: Mutated input.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    mutation_probability = {\"mutation_random_profile_perturbation\" : get_arg_value(\"make_mutation__mutation_random_profile_perturbation_probability\", None if mutation_probability is None else mutation_probability[\"mutation_random_profile_perturbation\"]),\n",
    "                            \"mutation_random_weights_perturbation\" : get_arg_value(\"make_mutation__mutation_random_weights_perturbation_probability\", None if mutation_probability is None else mutation_probability[\"mutation_random_weights_perturbation\"]),\n",
    "                            \"mutation_shrink_profiles\" : get_arg_value(\"make_mutation__mutation_shrink_profiles_probability\", None if mutation_probability is None else mutation_probability[\"mutation_shrink_profiles\"]),\n",
    "                            \"mutation_expand_profiles\" : get_arg_value(\"make_mutation__mutation_expand_profiles_probability\", None if mutation_probability is None else mutation_probability[\"mutation_expand_profiles\"]),\n",
    "                            \"mutation_partially_reverse_order\" : get_arg_value(\"make_mutation__mutation_partially_reverse_order_probability\", None if mutation_probability is None else mutation_probability[\"mutation_partially_reverse_order\"])}\n",
    "    \n",
    "    # Mutations are applied in random order\n",
    "    mutations = list(mutation_probability.keys())\n",
    "    numpy.random.shuffle(mutations)\n",
    "\n",
    "    # We apply the mutations (multiple can be applied)\n",
    "    mutated_solution = solution\n",
    "    for mutation in mutations :\n",
    "        if mutation in globals() :\n",
    "            if numpy.random.rand() < mutation_probability[mutation] :\n",
    "                mutated_solution = globals()[mutation](mutated_solution)\n",
    "        else :\n",
    "            sys.exit(\"Trying to perform nonexisting mutation: \" + str(mutation))\n",
    "    \n",
    "    # Done\n",
    "    return mutated_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_or_drop_children (parents, children, survival_probability=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Chooses which solutions are kept.\n",
    "        --\n",
    "        In:\n",
    "            * parents: Parents used to generate children, along with their fitnesses.\n",
    "            * children: Children to choose to keep or not, along with their fitnesses.\n",
    "            * survival_probability: Probability to keep a child, whatever happens.\n",
    "        Out:\n",
    "            * kept_children: Kept children.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    survival_probability = get_arg_value(\"keep_or_drop_children__survival_probability\", survival_probability)\n",
    "\n",
    "    # We check children one by one\n",
    "    kept_children = []\n",
    "    for child in children :\n",
    "    \n",
    "        # Each child has a probability to survive, whatever happens\n",
    "        if numpy.random.rand() < survival_probability :\n",
    "            kept_children += [child]\n",
    "        \n",
    "        # We keep children that are better than at least one parent\n",
    "        elif child[0] > min([parent[0] for parent in parents]) :\n",
    "            kept_children += [child]\n",
    "    \n",
    "    # Done\n",
    "    return kept_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_decision_maker (expected_results, alternatives, test_sets=[], return_k_best=None, population_size=None, stop_after_non_evolving=None, \n",
    "                             check_identical_ratio=None, nb_profiles=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Tries to estimate the decision maker using genetic algorithm and a few given comparisons.\n",
    "        --\n",
    "        In:\n",
    "            * expected_results: Provided comparisons, along with their preference relation.\n",
    "            * alternatives: List of alternatives to compute decision maker ranking vectors.\n",
    "            * test_sets: Test sets to evaluate decision maker on for summaries.\n",
    "            * return_k_best: Number of best profiles to return.\n",
    "            * population_size: Number of elements in the population for the GA.\n",
    "            * stop_after_non_evolving: Number of iterations before stopping if the best solution isn't improved.\n",
    "            * check_identical_ratio: Percentage of the solutions chosen by elitism that don't change at each iteration to consider nothing improved.\n",
    "            * nb_profiles: Number of profiles to give to random solutions.\n",
    "        Out:\n",
    "            * best_solutions: Best solutions found per iteration.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Retrieve command line default arguments\n",
    "    population_size = get_arg_value(\"estimate_decision_maker__population_size\", population_size)\n",
    "    return_k_best = get_arg_value(\"estimate_decision_maker__return_k_best\", return_k_best)\n",
    "    stop_after_non_evolving = get_arg_value(\"estimate_decision_maker__stop_after_non_evolving\", stop_after_non_evolving)\n",
    "    check_identical_ratio = get_arg_value(\"estimate_decision_maker__check_identical_ratio\", check_identical_ratio)\n",
    "    nb_profiles = get_arg_value(\"estimate_decision_maker__nb_profiles\", nb_profiles)\n",
    "    elitism_ratio = get_arg_value(\"prepare_new_population__elitism_ratio\", None)\n",
    "    check_identical_number = max(1, int(check_identical_ratio * int(elitism_ratio * population_size)))\n",
    "    parent_selection_strategy = get_arg_value(\"select_solutions__strategy\", None)\n",
    "    similarity_metric = get_arg_value(\"select_solutions__similarity_metric\", None)\n",
    "\n",
    "    # Prepare information for summary\n",
    "    if ARGS.debug_mode :\n",
    "        all_min_fitnesses, all_average_fitnesses, all_max_fitnesses = [], [], []\n",
    "        test_sets_fitnesses = [[] for i in range(len(test_sets))]\n",
    "    if ARGS.debug_mode or ARGS.save_diversity :    \n",
    "        diversities = []\n",
    "    \n",
    "    # Generate an initial population, sorted in decreasing fitness\n",
    "    population = generate_initial_population(population_size, nb_profiles, expected_results)\n",
    "\n",
    "    # Keep track of th iterations\n",
    "    nb_iterations = 0\n",
    "    nb_iterations_with_no_evolution = 0\n",
    "    \n",
    "    # EXP\n",
    "    def_pos = True\n",
    "    \n",
    "    # Iterate \"forever\"\n",
    "    while True :\n",
    "\n",
    "        # ONLY DEV\n",
    "        start = time.time()\n",
    "        \n",
    "        # Store information for summary\n",
    "        if ARGS.debug_mode :\n",
    "            all_min_fitnesses += [population[-1][0]]\n",
    "            all_average_fitnesses += [numpy.mean([solution[0] for solution in population])]\n",
    "            all_max_fitnesses += [population[0][0]]\n",
    "            for i in range(len(test_sets)) :\n",
    "                test_sets_fitnesses[i] += [compute_fitness(population[0][1], test_sets[i])]\n",
    "        \n",
    "        # We stop when all optima are found, or if the best solution does not evolve for some time\n",
    "        sub_population_bests = [population[i][0] for i in range(check_identical_number)]\n",
    "        if sum(sub_population_bests) == check_identical_number or nb_iterations_with_no_evolution == stop_after_non_evolving :\n",
    "        # if nb_iterations == 200 : # For plotting diversity\n",
    "            break\n",
    "            \n",
    "        # We initiate a new population based on the previous one\n",
    "        new_population = prepare_new_population(population, nb_profiles, expected_results)\n",
    "\n",
    "        # If we have a kernel-based probabilistic parent selection strategy, we compute the model with the generation's population\n",
    "        sampler = None\n",
    "        similarity_matrix = None\n",
    "        if parent_selection_strategy in {\"DPP\", \"DPP+roulette\"} :            \n",
    "            sampler = create_kDPP_model(population, similarity_metric, alternatives=alternatives)  \n",
    "            \n",
    "        similarity_matrix = sampler.A\n",
    "        \n",
    "        # Measure diversity given the metric's similarity matrix mean coeficient\n",
    "        if ARGS.debug_mode or ARGS.save_diversity :  \n",
    "            # We extract the similarity matrix from the sampler if it exists otherwise we compute it\n",
    "            similarity_matrix = sampler.A if sampler is not None else create_kDPP_model(population, similarity_metric, alternatives=alternatives).A\n",
    "            diversities.append(compute_diversity(similarity_matrix))\n",
    "            \n",
    "        # We create new children until we have a new population\n",
    "        while len(new_population) < len(population) :\n",
    "        \n",
    "            # We select solutions to mix\n",
    "            parents = select_solutions(population, sampler=sampler)\n",
    "            \n",
    "            # We create children\n",
    "            children = make_crossover(parents)\n",
    "            children = [make_mutation(child) for child in children]\n",
    "            children = [(compute_fitness(child, expected_results), child) for child in children]\n",
    "\n",
    "            # We inject some of them in the new population\n",
    "            new_population += keep_or_drop_children(parents, children)\n",
    "\n",
    "        # We update the population\n",
    "        new_population = sorted(new_population, key=lambda obj : -obj[0])\n",
    "        sub_new_population_bests = [new_population[i][0] for i in range(check_identical_number)]\n",
    "        if sub_population_bests == sub_new_population_bests :\n",
    "            nb_iterations_with_no_evolution += 1\n",
    "        else :\n",
    "            nb_iterations_with_no_evolution = 0\n",
    "        population = new_population[:population_size]\n",
    "\n",
    "        # Check if best training solutions generalize well\n",
    "        '''if ARGS.debug_mode :\n",
    "            if nb_iterations_with_no_evolution == 0 :\n",
    "                plot_bars([[solution[0] for solution in population]] + [[compute_fitness(solution[1], test_sets[i]) for solution in population] for i in range(len(test_sets))],\n",
    "                          [\"Train\"] + [\"Test \" + str(i + 1) for i in range(len(test_sets))],\n",
    "                          [\"dm\" + str(solution[1][\"id\"]) for solution in population],\n",
    "                          \"Fitness\",\n",
    "                          \"Population after iteration \" + str(len(all_min_fitnesses)))'''\n",
    "                \n",
    "        # ONLY DEV\n",
    "        end = time.time()\n",
    "        print(f'Iteration {nb_iterations} took {end - start} seconds.\\nNumber of iterations with no evolution: {nb_iterations_with_no_evolution}\\n')\n",
    "        def_pos = is_positive_definite(similarity_matrix)\n",
    "        print(f'Positive Definite: {def_pos}')\n",
    "        print(min(numpy.linalg.eigvals(similarity_matrix)))\n",
    "        print(max(numpy.linalg.eigvals(similarity_matrix)))\n",
    "        \n",
    "        # Increase iteration number\n",
    "        nb_iterations += 1\n",
    "        \n",
    "    # Summary\n",
    "    if ARGS.debug_mode :\n",
    "        dm_title = \"Best estimated\\nConcordance on training set: \" + str(population[0][0])\n",
    "        for i in range(len(test_sets)) :\n",
    "            dm_title += \"\\nConcordance on test set \" + str(i + 1) + \": \" + str(test_sets_fitnesses[i][-1])\n",
    "        plot_decision_maker(population[0][1], title=dm_title, file_name=ARGS.output_directory + \"decision_maker_estimated.png\")\n",
    "        plot_curves([list(range(len(all_min_fitnesses)))] * (3 + len(test_sets)),\n",
    "                    [all_max_fitnesses, all_average_fitnesses, all_min_fitnesses] + test_sets_fitnesses,\n",
    "                    [\"Max fitness in population on train set\", \"Average fitness in population on train set\", \"Min fitness in population on train set\"] + [\"Best model fitness on test set \" + str(i + 1) for i in range(len(test_sets))],\n",
    "                    [\"r-\", \"r--\", \"r:\"] + [\"b-\", \"g-\"][:len(test_sets)],\n",
    "                    xlabel=\"Iteration\",\n",
    "                    ylabel=\"Fitness\",\n",
    "                    file_name=ARGS.output_directory + \"fitnesses.png\")        \n",
    "        #Plot the mean of the pairwise similarities per generation\n",
    "        plot_curves([list(range(len(diversities)))], \n",
    "                    [[x[0] for x in diversities]], \n",
    "                    [\"Similarities Mean\"], \n",
    "                    [\"r-\"], \n",
    "                    xlabel=\"Iteration\", ylabel=\"Mean\", \n",
    "                    title=f\"Mean pairwise similarity with {similarity_metric} metric per iteration\\nParent selection strategy: {parent_selection_strategy}\",\n",
    "                    #vertical_asymptote=(nb_iterations-1)-nb_iterations_with_no_evolution,\n",
    "                    #vertical_asymptote_label=\"Best solution found\",\n",
    "                    file_name=ARGS.output_directory + f\"mean_plot_{parent_selection_strategy}_{similarity_metric}.png\",\n",
    "                    latex_name=ARGS.output_directory + f\"mean_plot_{parent_selection_strategy}_{similarity_metric}.tex\")\n",
    "        #Plot the standard deviation of the pairwise similarities per generation\n",
    "        plot_curves([list(range(len(diversities)))], \n",
    "                    [[x[1] for x in diversities]], \n",
    "                    [\"Similarities Standard Deviation\"], \n",
    "                    [\"b-\"], \n",
    "                    xlabel=\"Iteration\", ylabel=\"Standard Deviation\", \n",
    "                    title=f\"Pairwise similarity standard deviation with {similarity_metric} metric per iteration\\nParent selection strategy: {parent_selection_strategy}\",\n",
    "                    #vertical_asymptote=(nb_iterations-1)-nb_iterations_with_no_evolution,\n",
    "                    #vertical_asymptote_label=\"Best solution found\",\n",
    "                    file_name=ARGS.output_directory + f\"std_plot_{parent_selection_strategy}_{similarity_metric}.png\",\n",
    "                    latex_name=ARGS.output_directory + f\"std_plot_{parent_selection_strategy}_{similarity_metric}.tex\")\n",
    "        #Plot the variance of the pairwise similarities per generation\n",
    "        plot_curves([list(range(len(diversities)))], \n",
    "                    [[x[2] for x in diversities]], \n",
    "                    [\"Similarities Variance\"], \n",
    "                    [\"b-\"], \n",
    "                    xlabel=\"Iteration\", ylabel=\"Variance\", \n",
    "                    title=f\"Pairwise similarity variance with {similarity_metric} metric per iteration\\nParent selection strategy: {parent_selection_strategy}\",\n",
    "                    #vertical_asymptote=(nb_iterations-1)-nb_iterations_with_no_evolution,\n",
    "                    #vertical_asymptote_label=\"Best solution found\",\n",
    "                    file_name=ARGS.output_directory + f\"var_plot_{parent_selection_strategy}_{similarity_metric}.png\",\n",
    "                    latex_name=ARGS.output_directory + f\"var_plot_{parent_selection_strategy}_{similarity_metric}.tex\") \n",
    "    if ARGS.save_diversity :\n",
    "        #Save the mean of the pairwise similarities per generation\n",
    "        write_to_csv(data=[x[0] for x in diversities],\n",
    "                     file_name=f\"mean_data_{parent_selection_strategy}_{similarity_metric}.csv\")\n",
    "        #Save the standard deviation of the pairwise similarities per generation\n",
    "        write_to_csv(data=[x[1] for x in diversities],\n",
    "                     file_name=f\"std_data_{parent_selection_strategy}_{similarity_metric}.csv\")\n",
    "        #Save the variance of the pairwise similarities per generation\n",
    "        write_to_csv(data=[x[2] for x in diversities],\n",
    "                     file_name=f\"var_data_{parent_selection_strategy}_{similarity_metric}.csv\")        \n",
    "\n",
    "    # Done\n",
    "    best_solutions = population[:return_k_best]\n",
    "    return best_solutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Experiments</center></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create a problem</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define problem\n",
    "ground_truth_decision_maker = create_random_decision_maker(ARGS.nb_criteria, ARGS.nb_profiles)\n",
    "alternatives = [create_random_alternative(ARGS.nb_criteria) for i in range(ARGS.nb_alternatives)]\n",
    "training_set, sampling_matrix = subsample_comparisons(ground_truth_decision_maker, alternatives, ARGS.nb_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define as first test set what has not been sampled from the alternative comparisons\n",
    "test_set_1 = []\n",
    "if ARGS.eval_on_test_set_1 :\n",
    "    for i in range(ARGS.nb_alternatives) :\n",
    "        for j in range(i + 1, ARGS.nb_alternatives) :\n",
    "            if sampling_matrix[i, j] == 0 :\n",
    "                test_set_1 += [(alternatives[i], alternatives[j], check_preference(ground_truth_decision_maker, alternatives[i], alternatives[j])[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define as second test set a all comparisons of unseen alternatives\n",
    "test_set_2 = []\n",
    "if ARGS.nb_alternatives_test_set_2 > 0 :\n",
    "    unseen_alternatives = [create_random_alternative(ARGS.nb_criteria) for i in range(ARGS.nb_alternatives_test_set_2)]\n",
    "    test_set_2, _ = subsample_comparisons(ground_truth_decision_maker, unseen_alternatives, int(ARGS.nb_alternatives_test_set_2 * (ARGS.nb_alternatives_test_set_2 - 1) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate used tests sets in a list\n",
    "test_sets = []\n",
    "for test_set in [test_set_1, test_set_2] :\n",
    "    if len(test_set) > 0 :\n",
    "        test_sets.append(test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Analyze it a bit</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth\n",
    "if ARGS.debug_mode :\n",
    "    plot_decision_maker(ground_truth_decision_maker, title=\"Ground truth\", file_name=ARGS.output_directory + \"decision_maker_ground_truth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check which profiles are useful\n",
    "if ARGS.debug_mode :\n",
    "    discriminating_profiles, preferences = compute_all_preferences(ground_truth_decision_maker, alternatives)\n",
    "    plot_matrix(discriminating_profiles, rows_labels=[\"a\" + str(alternative[\"id\"]) for alternative in alternatives], cols_labels=[\"a\" + str(alternative[\"id\"]) for alternative in alternatives], title=\"Index of the discriminating profile (ground truth DM)\", round_values=0, file_name=ARGS.output_directory + \"discriminating_profiles_ground_truth.png\")\n",
    "    plot_matrix(preferences, rows_labels=[\"a\" + str(alternative[\"id\"]) for alternative in alternatives], cols_labels=[\"a\" + str(alternative[\"id\"]) for alternative in alternatives], title=\"Preference map (ground truth DM)\", round_values=0, file_name=ARGS.output_directory + \"preferences_ground_truth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if sampling is sufficient\n",
    "if ARGS.debug_mode :\n",
    "    plot_matrix(sampling_matrix, rows_labels=[\"a\" + str(alternative[\"id\"]) for alternative in alternatives], cols_labels=[\"a\" + str(alternative[\"id\"]) for alternative in alternatives], title=\"Subsampled comparisons\", round_values=0, file_name=ARGS.output_directory + \"training_set.png\")\n",
    "    plot_matrix(numpy.sum(sampling_matrix, axis=0).reshape(1, ARGS.nb_alternatives), cols_labels=[\"a\" + str(alternative[\"id\"]) for alternative in alternatives], title=\"Number of appearances in comparisons\\n\\n\", round_values=0, file_name=ARGS.output_directory + \"training_set_counts.png\")\n",
    "    plot_matrix(sparse.csgraph.connected_components(sparse.csr_matrix(sampling_matrix), directed=False, return_labels=True)[1].reshape(1, ARGS.nb_alternatives), cols_labels=[\"a\" + str(alternative[\"id\"]) for alternative in alternatives], title=\"Connected components of alternatives\\n\\n\", round_values=0, file_name=ARGS.output_directory + \"training_set_connected_components.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Solve it</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 took 0.563739538192749 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: True\n",
      "0.09202439854622368\n",
      "37.738879057585045\n",
      "Iteration 1 took 0.6636755466461182 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.4164233685864888e-16-2.003162594001076e-17j)\n",
      "(39.35772552803576+0j)\n",
      "Iteration 2 took 0.8221628665924072 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.627062615409906e-16+0j)\n",
      "(34.98878576946357+0j)\n",
      "Iteration 3 took 1.0584378242492676 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.271903561920901e-16+0j)\n",
      "(38.023839283893246+0j)\n",
      "Iteration 4 took 1.0907676219940186 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.5012063672367207e-16+0j)\n",
      "(34.914108288589816+0j)\n",
      "Iteration 5 took 0.8466596603393555 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-5.507773386373959e-17-2.3682516021682808e-17j)\n",
      "(39.06056732460419+0j)\n",
      "Iteration 6 took 0.8794276714324951 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.3645523086634903e-16+0j)\n",
      "(37.92480710619216+0j)\n",
      "Iteration 7 took 0.761164665222168 seconds.\n",
      "Number of iterations with no evolution: 1\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.1225927319114427e-16+0j)\n",
      "(37.25347479385361+0j)\n",
      "Iteration 8 took 0.7748606204986572 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.9602010230672832e-16+0j)\n",
      "(40.04367319971938+0j)\n",
      "Iteration 9 took 0.8294947147369385 seconds.\n",
      "Number of iterations with no evolution: 1\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.460142039118113e-16-1.8033928445470514e-17j)\n",
      "(40.65753286105299+0j)\n",
      "Iteration 10 took 0.8715314865112305 seconds.\n",
      "Number of iterations with no evolution: 2\n",
      "\n",
      "Positive Definite: False\n",
      "(-4.821872553101468e-17-1.9546794900319388e-16j)\n",
      "(43.13702212226736+0j)\n",
      "Iteration 11 took 0.7150974273681641 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.1009604720927052e-15+0j)\n",
      "(44.93853599427756+0j)\n",
      "Iteration 12 took 0.5273711681365967 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.4232177777738084e-16-2.98824696664165e-17j)\n",
      "(42.89946305688301+0j)\n",
      "Iteration 13 took 0.6542863845825195 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-8.023158764809973e-17+0j)\n",
      "(42.70060245717023+0j)\n",
      "Iteration 14 took 0.834632396697998 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.3434273236171895e-16+0j)\n",
      "(46.504146562261816+0j)\n",
      "Iteration 15 took 0.8569357395172119 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-8.283368778895688e-16+0j)\n",
      "(49.93588823091277+0j)\n",
      "Iteration 16 took 0.6993100643157959 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-9.33287653624281e-16+0j)\n",
      "(47.57982131013908+0j)\n",
      "Iteration 17 took 0.589867115020752 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-4.814020169995328e-16+0j)\n",
      "(50.32211137866439+0j)\n",
      "Iteration 18 took 0.8667473793029785 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-4.459294248058873e-16+0j)\n",
      "(46.56512071527386+0j)\n",
      "Iteration 19 took 0.7220637798309326 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-3.509563873807316e-16+0j)\n",
      "(44.49590624744775+0j)\n",
      "Iteration 20 took 0.856743335723877 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-6.524334894497481e-16+0j)\n",
      "(45.18049054314746+0j)\n",
      "Iteration 21 took 0.7793769836425781 seconds.\n",
      "Number of iterations with no evolution: 1\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.403354364051929e-16-4.792732066579932e-16j)\n",
      "(42.97243489893606+0j)\n",
      "Iteration 22 took 0.7314176559448242 seconds.\n",
      "Number of iterations with no evolution: 2\n",
      "\n",
      "Positive Definite: False\n",
      "(-3.068907509101524e-16-1.0432780681995108e-15j)\n",
      "(46.17386137976031+0j)\n",
      "Iteration 23 took 0.8555507659912109 seconds.\n",
      "Number of iterations with no evolution: 3\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.71765462660061e-16+0j)\n",
      "(47.59292032915542+0j)\n",
      "Iteration 24 took 0.7657999992370605 seconds.\n",
      "Number of iterations with no evolution: 4\n",
      "\n",
      "Positive Definite: False\n",
      "(-5.696201955351031e-16+0j)\n",
      "(49.78682087880062+0j)\n",
      "Iteration 25 took 0.973031759262085 seconds.\n",
      "Number of iterations with no evolution: 5\n",
      "\n",
      "Positive Definite: False\n",
      "(-5.906965835791432e-16+0j)\n",
      "(52.42553933828266+0j)\n",
      "Iteration 26 took 0.8110716342926025 seconds.\n",
      "Number of iterations with no evolution: 6\n",
      "\n",
      "Positive Definite: False\n",
      "(-3.2694880173390107e-16+0j)\n",
      "(51.721453317556296+0j)\n",
      "Iteration 27 took 0.9068572521209717 seconds.\n",
      "Number of iterations with no evolution: 7\n",
      "\n",
      "Positive Definite: False\n",
      "(-3.6835985120484793e-16+0j)\n",
      "(52.22979042604648+0j)\n",
      "Iteration 28 took 0.9071195125579834 seconds.\n",
      "Number of iterations with no evolution: 8\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.264095236132824e-16-6.446781677598201e-16j)\n",
      "(50.62141269631454+0j)\n",
      "Iteration 29 took 0.7310426235198975 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-8.397235074143077e-16+0j)\n",
      "(58.45231488687548+0j)\n",
      "Iteration 30 took 0.7953557968139648 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.078146178722289e-16-7.287462949805558e-17j)\n",
      "(48.95937072898307+0j)\n",
      "Iteration 31 took 0.7409894466400146 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.1689320982714108e-16+0j)\n",
      "(51.56843172951948+0j)\n",
      "Iteration 32 took 0.7503705024719238 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-9.370303597308031e-17-1.710713577542487e-16j)\n",
      "(49.47746473161647+0j)\n",
      "Iteration 33 took 0.6362121105194092 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-4.680840633670275e-17-9.389090196915052e-17j)\n",
      "(53.58365904859453+0j)\n",
      "Iteration 34 took 0.7887916564941406 seconds.\n",
      "Number of iterations with no evolution: 1\n",
      "\n",
      "Positive Definite: False\n",
      "(-6.735480338003884e-17-1.1053326713008123e-17j)\n",
      "(48.61783450802478+0j)\n",
      "Iteration 35 took 0.75469970703125 seconds.\n",
      "Number of iterations with no evolution: 2\n",
      "\n",
      "Positive Definite: False\n",
      "(-7.431194149006476e-17-9.620847526021504e-18j)\n",
      "(48.500730839596216+0j)\n",
      "Iteration 36 took 0.693737268447876 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-7.615799920764316e-17+0j)\n",
      "(48.10112547971936+0j)\n",
      "Iteration 37 took 0.7810206413269043 seconds.\n",
      "Number of iterations with no evolution: 1\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.411700988017502e-16+0j)\n",
      "(49.22747604303321+0j)\n",
      "Iteration 38 took 0.6882526874542236 seconds.\n",
      "Number of iterations with no evolution: 2\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.4219788055608687e-16+0j)\n",
      "(52.62484314523657+0j)\n",
      "Iteration 39 took 0.7632031440734863 seconds.\n",
      "Number of iterations with no evolution: 3\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.688331363322615e-16+0j)\n",
      "(51.653725583001844+0j)\n",
      "Iteration 40 took 0.6562473773956299 seconds.\n",
      "Number of iterations with no evolution: 4\n",
      "\n",
      "Positive Definite: False\n",
      "(-4.734590906494238e-17-1.662263123063697e-17j)\n",
      "(53.544879179933126+0j)\n",
      "Iteration 41 took 0.6935362815856934 seconds.\n",
      "Number of iterations with no evolution: 5\n",
      "\n",
      "Positive Definite: False\n",
      "(-6.175056998139252e-17+0j)\n",
      "(49.20551081258992+0j)\n",
      "Iteration 42 took 0.6729321479797363 seconds.\n",
      "Number of iterations with no evolution: 6\n",
      "\n",
      "Positive Definite: False\n",
      "(-3.4529794767174447e-16+0j)\n",
      "(49.74918459625338+0j)\n",
      "Iteration 43 took 0.5513148307800293 seconds.\n",
      "Number of iterations with no evolution: 7\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.6315483415990205e-17-2.112115067717344e-16j)\n",
      "(52.23577379182388+0j)\n",
      "Iteration 44 took 0.5642755031585693 seconds.\n",
      "Number of iterations with no evolution: 8\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.809963488916806e-17-1.7329039123200418e-17j)\n",
      "(52.28003288856881+0j)\n",
      "Iteration 45 took 0.6442279815673828 seconds.\n",
      "Number of iterations with no evolution: 9\n",
      "\n",
      "Positive Definite: False\n",
      "(-3.028143770502933e-17-1.0358314022661844e-17j)\n",
      "(50.76255778489451+0j)\n",
      "Iteration 46 took 0.589000940322876 seconds.\n",
      "Number of iterations with no evolution: 10\n",
      "\n",
      "Positive Definite: False\n",
      "(-8.831302333281447e-17+0j)\n",
      "(48.90937043739769+0j)\n",
      "Iteration 47 took 0.8219406604766846 seconds.\n",
      "Number of iterations with no evolution: 11\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.496519585031035e-16+0j)\n",
      "(50.65021406629666+0j)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48 took 0.6319379806518555 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.8175532664854364e-16+0j)\n",
      "(50.21589683103432+0j)\n",
      "Iteration 49 took 0.8257336616516113 seconds.\n",
      "Number of iterations with no evolution: 1\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.558903923181398e-16+0j)\n",
      "(51.71269724784022+0j)\n",
      "Iteration 50 took 0.6816244125366211 seconds.\n",
      "Number of iterations with no evolution: 2\n",
      "\n",
      "Positive Definite: False\n",
      "(-6.516564705888718e-17+0j)\n",
      "(50.17337828913888+0j)\n",
      "Iteration 51 took 0.7513339519500732 seconds.\n",
      "Number of iterations with no evolution: 3\n",
      "\n",
      "Positive Definite: False\n",
      "(-2.30731195721454e-16+0j)\n",
      "(58.2130466537703+0j)\n",
      "Iteration 52 took 0.6395955085754395 seconds.\n",
      "Number of iterations with no evolution: 0\n",
      "\n",
      "Positive Definite: False\n",
      "(-1.5552938602244853e-16+0j)\n",
      "(58.122676829738+0j)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-9d7ced9f7a01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mstart_profiling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mestimated_decision_makers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimate_decision_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malternatives\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_sets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mstop_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mARGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug_mode\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-7e48524dfe91>\u001b[0m in \u001b[0;36mestimate_decision_maker\u001b[1;34m(expected_results, alternatives, test_sets, return_k_best, population_size, stop_after_non_evolving, check_identical_ratio, nb_profiles)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# We select solutions to mix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mparents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_solutions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# We create children\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-0c941af72aa6>\u001b[0m in \u001b[0;36mselect_solutions\u001b[1;34m(population, nb_solutions, strategy, sampler)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Use a metric-based similarity matrix of all decision makers as a DPP-sampling kernel to encourage diversity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"DPP\"\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mselected_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_k\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_solutions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mselected_solutions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselected_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pydpp\\dpp.py\u001b[0m in \u001b[0;36msample_k\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cos-sim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0meigen_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meigen_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0meigen_vals\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meigen_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0meigen_vec\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meigen_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meig\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36meig\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1299\u001b[0m         _raise_linalgerror_eigenvalues_nonconvergence)\n\u001b[0;32m   1300\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->DD'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->DD'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Solve the problem\n",
    "if ARGS.debug_mode :\n",
    "    start_profiling()\n",
    "start_time = time.process_time()\n",
    "estimated_decision_makers = estimate_decision_maker(training_set, alternatives, test_sets=test_sets)\n",
    "stop_time = time.process_time()\n",
    "if ARGS.debug_mode :\n",
    "    stop_profiling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show all decision makers\n",
    "if ARGS.debug_mode :\n",
    "    for estimated_decision_maker in estimated_decision_makers :\n",
    "        plot_decision_maker(estimated_decision_maker[1], title=\"Fitness on training set: \" + str(estimated_decision_maker[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We output the best model final performance on all datasets\n",
    "results = {}\n",
    "results[\"time\"] = stop_time - start_time\n",
    "results[\"train\"] = estimated_decision_makers[0][0]\n",
    "if len(test_set_1) > 0 :\n",
    "    results[\"test_1\"] = compute_fitness(estimated_decision_makers[0][1], test_set_1)\n",
    "if len(test_set_2) > 0 :\n",
    "    results[\"test_2\"] = compute_fitness(estimated_decision_makers[0][1], test_set_2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda117",
   "language": "python",
   "name": "cuda117"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ce830cb533ad4dd8f0ad2e03c0a5d4f7bb85841771f69c324bbac9b0da47fe6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
